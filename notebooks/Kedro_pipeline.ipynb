{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-14 08:42:52,179 - kedro.io.data_catalog - INFO - Loading data from `news` (CSVDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               news  labels\n",
       "0           0  I was wondering if anyone out there could enli...       7\n",
       "1           1  A fair number of brave souls who upgraded thei...       4\n",
       "2           2  well folks, my mac plus finally gave up the gh...       4\n",
       "3           3  \\nDo you have Weitek's address/phone number?  ...       1\n",
       "4           4  From article <C5owCB.n3p@world.std.com>, by to...      14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.load('news').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': Pipeline([\n",
       " Node(split_data, ['steam_reviews', 'params:target', 'params:columns'], {'train_x': 'train_x', 'train_y': 'train_y', 'test_x': 'test_x', 'test_y': 'test_y'}, None)\n",
       " ]),\n",
       " 'prep': Pipeline([\n",
       " Node(get_DF, ['train_x', 'params:preprocess_out'], 'df_sents', None),\n",
       " Node(get_DF, ['test_x', 'params:preprocess_out'], 'df_sents_test', None)\n",
       " ]),\n",
       " 'ds': Pipeline([\n",
       " Node(train_model, ['train_x', 'train_y', 'parameters'], 'example_model', None),\n",
       " Node(predict, {'model': 'example_model', 'test_x': 'example_test_x'}, 'example_predictions', None),\n",
       " Node(report_accuracy, ['example_predictions', 'example_test_y'], None, None)\n",
       " ]),\n",
       " 'vec': Pipeline([\n",
       " Node(get_distillBert, ['df_sents'], 'distill_vec', None),\n",
       " Node(get_distillBert, ['df_sents_test'], 'distill_vec_t', None),\n",
       " Node(train_Corex, ['params:n_topics', 'df_sents'], {'corex_model': 'corex_model', 'countvectorizer': 'countvectorizer'}, None),\n",
       " Node(predict_Corex, ['df_sents_test', 'corex_model', 'countvectorizer'], {'corex_vecs_1': 'corex_vecs_1_t', 'corex_vecs_2': 'corex_vecs_2_t', 'textID': 'textID_t'}, None),\n",
       " Node(predict_Corex, ['df_sents', 'corex_model', 'countvectorizer'], {'corex_vecs_1': 'corex_vecs_1', 'corex_vecs_2': 'corex_vecs_2', 'textID': 'textID'}, None),\n",
       " Node(autoencoder, ['corex_vecs_2', 'distill_vec'], {'ae': 'auto_encoder_model'}, None),\n",
       " Node(ae_predict, ['corex_vecs_2_t', 'distill_vec_t', 'textID_t', 'auto_encoder_model'], {'vec': 'corex_encoded_t', 'uniqueID': 'textIDA_t'}, None),\n",
       " Node(ae_predict, ['corex_vecs_2', 'distill_vec', 'textID', 'auto_encoder_model'], {'vec': 'corex_encoded', 'uniqueID': 'textIDA'}, None),\n",
       " Node(get_mean_pooling, ['corex_encoded', 'textIDA'], 'corex_pooled', None),\n",
       " Node(get_mean_pooling, ['corex_encoded_t', 'textIDA_t'], 'corex_pooled_t', None)\n",
       " ]),\n",
       " '__default__': Pipeline([\n",
       " Node(split_data, ['steam_reviews', 'params:target', 'params:columns'], {'train_x': 'train_x', 'train_y': 'train_y', 'test_x': 'test_x', 'test_y': 'test_y'}, None),\n",
       " Node(get_DF, ['train_x', 'params:preprocess_out'], 'df_sents', None),\n",
       " Node(get_DF, ['test_x', 'params:preprocess_out'], 'df_sents_test', None),\n",
       " Node(get_distillBert, ['df_sents'], 'distill_vec', None),\n",
       " Node(get_distillBert, ['df_sents_test'], 'distill_vec_t', None),\n",
       " Node(train_Corex, ['params:n_topics', 'df_sents'], {'corex_model': 'corex_model', 'countvectorizer': 'countvectorizer'}, None),\n",
       " Node(predict_Corex, ['df_sents_test', 'corex_model', 'countvectorizer'], {'corex_vecs_1': 'corex_vecs_1_t', 'corex_vecs_2': 'corex_vecs_2_t', 'textID': 'textID_t'}, None),\n",
       " Node(predict_Corex, ['df_sents', 'corex_model', 'countvectorizer'], {'corex_vecs_1': 'corex_vecs_1', 'corex_vecs_2': 'corex_vecs_2', 'textID': 'textID'}, None),\n",
       " Node(autoencoder, ['corex_vecs_2', 'distill_vec'], {'ae': 'auto_encoder_model'}, None),\n",
       " Node(ae_predict, ['corex_vecs_2_t', 'distill_vec_t', 'textID_t', 'auto_encoder_model'], {'vec': 'corex_encoded_t', 'uniqueID': 'textIDA_t'}, None),\n",
       " ...\n",
       " ])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-18 19:34:07,744 - root - INFO - ** Kedro project nlpipe\n",
      "2020-06-18 19:34:07,788 - kedro.io.data_catalog - INFO - Loading data from `steam_reviews` (CSVDataSet)...\n",
      "2020-06-18 19:34:09,333 - kedro.io.data_catalog - INFO - Loading data from `params:target` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,334 - kedro.io.data_catalog - INFO - Loading data from `params:columns` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,335 - kedro.pipeline.node - INFO - Running node: split_data([params:columns,params:target,steam_reviews]) -> [test_x,test_y,train_x,train_y]\n",
      "2020-06-18 19:34:09,428 - kedro.io.data_catalog - INFO - Saving data to `train_x` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,437 - kedro.io.data_catalog - INFO - Saving data to `train_y` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,440 - kedro.io.data_catalog - INFO - Saving data to `test_x` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,444 - kedro.io.data_catalog - INFO - Saving data to `test_y` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,471 - kedro.runner.sequential_runner - INFO - Completed 1 out of 16 tasks\n",
      "2020-06-18 19:34:09,472 - kedro.io.data_catalog - INFO - Loading data from `train_x` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,480 - kedro.io.data_catalog - INFO - Loading data from `params:preprocess_out` (MemoryDataSet)...\n",
      "2020-06-18 19:34:09,482 - kedro.pipeline.node - INFO - Running node: get_DF([params:preprocess_out,train_x]) -> [df_sents]\n",
      "2020-06-18 19:34:43,474 - kedro.io.data_catalog - INFO - Saving data to `df_sents` (MemoryDataSet)...\n",
      "2020-06-18 19:34:43,476 - kedro.runner.sequential_runner - INFO - Completed 2 out of 16 tasks\n",
      "2020-06-18 19:34:43,477 - kedro.io.data_catalog - INFO - Loading data from `test_x` (MemoryDataSet)...\n",
      "2020-06-18 19:34:43,480 - kedro.io.data_catalog - INFO - Loading data from `params:preprocess_out` (MemoryDataSet)...\n",
      "2020-06-18 19:34:43,481 - kedro.pipeline.node - INFO - Running node: get_DF([params:preprocess_out,test_x]) -> [df_sents_test]\n",
      "2020-06-18 19:34:51,518 - kedro.io.data_catalog - INFO - Saving data to `df_sents_test` (MemoryDataSet)...\n",
      "2020-06-18 19:34:51,520 - kedro.runner.sequential_runner - INFO - Completed 3 out of 16 tasks\n",
      "2020-06-18 19:34:51,521 - kedro.io.data_catalog - INFO - Loading data from `df_sents` (MemoryDataSet)...\n",
      "2020-06-18 19:34:51,523 - kedro.pipeline.node - INFO - Running node: get_distillBert([df_sents]) -> [distill_vec]\n",
      "2020-06-18 19:34:51,524 - root - INFO - Load pretrained SentenceTransformer: distilbert-base-nli-stsb-mean-tokens\n",
      "2020-06-18 19:34:51,525 - root - INFO - Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "2020-06-18 19:34:51,527 - root - INFO - Load SentenceTransformer from folder: /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip\n",
      "2020-06-18 19:34:51,545 - transformers.configuration_utils - INFO - loading configuration file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/config.json\n",
      "2020-06-18 19:34:51,546 - transformers.configuration_utils - INFO - Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-06-18 19:34:51,547 - transformers.modeling_utils - INFO - loading weights file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/pytorch_model.bin\n",
      "2020-06-18 19:34:52,409 - transformers.tokenization_utils - INFO - Model name '/Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT' not found in model shortcut name list (distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased). Assuming '/Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-06-18 19:34:52,411 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/vocab.txt\n",
      "2020-06-18 19:34:52,412 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/added_tokens.json\n",
      "2020-06-18 19:34:52,413 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/special_tokens_map.json\n",
      "2020-06-18 19:34:52,414 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/tokenizer_config.json\n",
      "2020-06-18 19:34:52,471 - root - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1666/1666 [02:29<00:00, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-18 19:37:22,556 - kedro.io.data_catalog - INFO - Saving data to `distill_vec` (MemoryDataSet)...\n",
      "2020-06-18 19:37:22,591 - kedro.runner.sequential_runner - INFO - Completed 4 out of 16 tasks\n",
      "2020-06-18 19:37:22,592 - kedro.io.data_catalog - INFO - Loading data from `df_sents_test` (MemoryDataSet)...\n",
      "2020-06-18 19:37:22,594 - kedro.pipeline.node - INFO - Running node: get_distillBert([df_sents_test]) -> [distill_vec_t]\n",
      "2020-06-18 19:37:22,596 - root - INFO - Load pretrained SentenceTransformer: distilbert-base-nli-stsb-mean-tokens\n",
      "2020-06-18 19:37:22,597 - root - INFO - Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "2020-06-18 19:37:22,600 - root - INFO - Load SentenceTransformer from folder: /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip\n",
      "2020-06-18 19:37:22,603 - transformers.configuration_utils - INFO - loading configuration file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/config.json\n",
      "2020-06-18 19:37:22,604 - transformers.configuration_utils - INFO - Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-06-18 19:37:22,606 - transformers.modeling_utils - INFO - loading weights file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-18 19:37:23,675 - transformers.tokenization_utils - INFO - Model name '/Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT' not found in model shortcut name list (distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased). Assuming '/Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-06-18 19:37:23,677 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/vocab.txt\n",
      "2020-06-18 19:37:23,678 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/added_tokens.json\n",
      "2020-06-18 19:37:23,679 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/special_tokens_map.json\n",
      "2020-06-18 19:37:23,682 - transformers.tokenization_utils - INFO - loading file /Users/karthik/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_DistilBERT/tokenizer_config.json\n",
      "2020-06-18 19:37:23,752 - root - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 387/387 [00:39<00:00,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-18 19:38:03,175 - kedro.io.data_catalog - INFO - Saving data to `distill_vec_t` (MemoryDataSet)...\n",
      "2020-06-18 19:38:03,185 - kedro.runner.sequential_runner - INFO - Completed 5 out of 16 tasks\n",
      "2020-06-18 19:38:03,186 - kedro.io.data_catalog - INFO - Loading data from `params:n_topics` (MemoryDataSet)...\n",
      "2020-06-18 19:38:03,187 - kedro.io.data_catalog - INFO - Loading data from `df_sents` (MemoryDataSet)...\n",
      "2020-06-18 19:38:03,190 - kedro.pipeline.node - INFO - Running node: train_Corex([df_sents,params:n_topics]) -> [corex_model,countvectorizer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13326\n",
      "WARNING: Some words never appear (or always appear)\n",
      "2020-06-18 19:38:45,123 - kedro.io.data_catalog - INFO - Saving data to `corex_model` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,168 - kedro.io.data_catalog - INFO - Saving data to `countvectorizer` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,208 - kedro.runner.sequential_runner - INFO - Completed 6 out of 16 tasks\n",
      "2020-06-18 19:38:45,209 - kedro.io.data_catalog - INFO - Loading data from `df_sents_test` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,211 - kedro.io.data_catalog - INFO - Loading data from `corex_model` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,261 - kedro.io.data_catalog - INFO - Loading data from `countvectorizer` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,302 - kedro.pipeline.node - INFO - Running node: predict_Corex([corex_model,countvectorizer,df_sents_test]) -> [corex_vecs_1_t,corex_vecs_2_t,textID_t]\n",
      "2020-06-18 19:38:45,360 - kedro.io.data_catalog - INFO - Saving data to `corex_vecs_1_t` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,361 - kedro.io.data_catalog - INFO - Saving data to `corex_vecs_2_t` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,362 - kedro.io.data_catalog - INFO - Saving data to `textID_t` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,365 - kedro.runner.sequential_runner - INFO - Completed 7 out of 16 tasks\n",
      "2020-06-18 19:38:45,366 - kedro.io.data_catalog - INFO - Loading data from `df_sents` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,367 - kedro.io.data_catalog - INFO - Loading data from `corex_model` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,416 - kedro.io.data_catalog - INFO - Loading data from `countvectorizer` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,457 - kedro.pipeline.node - INFO - Running node: predict_Corex([corex_model,countvectorizer,df_sents]) -> [corex_vecs_1,corex_vecs_2,textID]\n",
      "2020-06-18 19:38:45,628 - kedro.io.data_catalog - INFO - Saving data to `corex_vecs_1` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,630 - kedro.io.data_catalog - INFO - Saving data to `corex_vecs_2` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,631 - kedro.io.data_catalog - INFO - Saving data to `textID` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,643 - kedro.runner.sequential_runner - INFO - Completed 8 out of 16 tasks\n",
      "2020-06-18 19:38:45,644 - kedro.io.data_catalog - INFO - Loading data from `corex_vecs_2` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,645 - kedro.io.data_catalog - INFO - Loading data from `distill_vec` (MemoryDataSet)...\n",
      "2020-06-18 19:38:45,669 - kedro.pipeline.node - INFO - Running node: autoencoder([corex_vecs_2,distill_vec]) -> [auto_encoder_model]\n",
      "(13326, 30)\n",
      "(13326, 768)\n",
      "(13326, 798)\n",
      "Fitting Autoencoder ...\n",
      "Fitting Autoencoder Done!\n",
      "2020-06-18 19:39:42,845 - kedro.io.data_catalog - INFO - Saving data to `auto_encoder_model` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,855 - kedro.runner.sequential_runner - INFO - Completed 9 out of 16 tasks\n",
      "2020-06-18 19:39:42,855 - kedro.io.data_catalog - INFO - Loading data from `corex_vecs_2_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,856 - kedro.io.data_catalog - INFO - Loading data from `distill_vec_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,863 - kedro.io.data_catalog - INFO - Loading data from `textID_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,866 - kedro.io.data_catalog - INFO - Loading data from `auto_encoder_model` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,875 - kedro.pipeline.node - INFO - Running node: ae_predict([auto_encoder_model,corex_vecs_2_t,distill_vec_t,textID_t]) -> [corex_encoded_t,textIDA_t]\n",
      "(3092, 30)\n",
      "(3092, 768)\n",
      "2020-06-18 19:39:42,931 - kedro.io.data_catalog - INFO - Saving data to `corex_encoded_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,932 - kedro.io.data_catalog - INFO - Saving data to `textIDA_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,935 - kedro.runner.sequential_runner - INFO - Completed 10 out of 16 tasks\n",
      "2020-06-18 19:39:42,936 - kedro.io.data_catalog - INFO - Loading data from `corex_vecs_2` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,937 - kedro.io.data_catalog - INFO - Loading data from `distill_vec` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,944 - kedro.io.data_catalog - INFO - Loading data from `textID` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,952 - kedro.io.data_catalog - INFO - Loading data from `auto_encoder_model` (MemoryDataSet)...\n",
      "2020-06-18 19:39:42,960 - kedro.pipeline.node - INFO - Running node: ae_predict([auto_encoder_model,corex_vecs_2,distill_vec,textID]) -> [corex_encoded,textIDA]\n",
      "(13326, 30)\n",
      "(13326, 768)\n",
      "2020-06-18 19:39:43,087 - kedro.io.data_catalog - INFO - Saving data to `corex_encoded` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,090 - kedro.io.data_catalog - INFO - Saving data to `textIDA` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,105 - kedro.runner.sequential_runner - INFO - Completed 11 out of 16 tasks\n",
      "2020-06-18 19:39:43,105 - kedro.io.data_catalog - INFO - Loading data from `corex_encoded` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,106 - kedro.io.data_catalog - INFO - Loading data from `textIDA` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,115 - kedro.pipeline.node - INFO - Running node: get_mean_pooling([corex_encoded,textIDA]) -> [corex_pooled]\n",
      "(13326, 2)\n",
      "(3479, 64)\n",
      "2020-06-18 19:39:43,871 - kedro.io.data_catalog - INFO - Saving data to `corex_pooled` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,873 - kedro.runner.sequential_runner - INFO - Completed 12 out of 16 tasks\n",
      "2020-06-18 19:39:43,874 - kedro.io.data_catalog - INFO - Loading data from `corex_encoded_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,876 - kedro.io.data_catalog - INFO - Loading data from `textIDA_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:43,879 - kedro.pipeline.node - INFO - Running node: get_mean_pooling([corex_encoded_t,textIDA_t]) -> [corex_pooled_t]\n",
      "(3092, 2)\n",
      "(870, 64)\n",
      "2020-06-18 19:39:44,070 - kedro.io.data_catalog - INFO - Saving data to `corex_pooled_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:44,074 - kedro.runner.sequential_runner - INFO - Completed 13 out of 16 tasks\n",
      "2020-06-18 19:39:44,075 - kedro.io.data_catalog - INFO - Loading data from `corex_pooled` (MemoryDataSet)...\n",
      "2020-06-18 19:39:44,076 - kedro.io.data_catalog - INFO - Loading data from `train_y` (MemoryDataSet)...\n",
      "2020-06-18 19:39:44,079 - kedro.pipeline.node - INFO - Running node: RF_train([corex_pooled,train_y]) -> [RF_model]\n",
      "2020-06-18 19:39:46,109 - kedro.io.data_catalog - INFO - Saving data to `RF_model` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,126 - kedro.runner.sequential_runner - INFO - Completed 14 out of 16 tasks\n",
      "2020-06-18 19:39:46,127 - kedro.io.data_catalog - INFO - Loading data from `RF_model` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,136 - kedro.io.data_catalog - INFO - Loading data from `corex_pooled_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,138 - kedro.pipeline.node - INFO - Running node: model_predict([RF_model,corex_pooled_t]) -> [predictions]\n",
      "2020-06-18 19:39:46,141 - kedro.io.data_catalog - INFO - Saving data to `predictions` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,143 - kedro.runner.sequential_runner - INFO - Completed 15 out of 16 tasks\n",
      "2020-06-18 19:39:46,143 - kedro.io.data_catalog - INFO - Loading data from `test_y` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,145 - kedro.io.data_catalog - INFO - Loading data from `predictions` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,146 - kedro.pipeline.node - INFO - Running node: report_gen([predictions,test_y]) -> [report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67       271\n",
      "           1       0.83      0.92      0.87       599\n",
      "\n",
      "    accuracy                           0.82       870\n",
      "   macro avg       0.80      0.76      0.77       870\n",
      "weighted avg       0.81      0.82      0.81       870\n",
      "\n",
      "2020-06-18 19:39:46,156 - kedro.io.data_catalog - INFO - Saving data to `report` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,157 - kedro.runner.sequential_runner - INFO - Completed 16 out of 16 tasks\n",
      "2020-06-18 19:39:46,158 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.\n",
      "2020-06-18 19:39:46,159 - kedro.io.data_catalog - INFO - Loading data from `corex_vecs_1_t` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,160 - kedro.io.data_catalog - INFO - Loading data from `report` (MemoryDataSet)...\n",
      "2020-06-18 19:39:46,161 - kedro.io.data_catalog - INFO - Loading data from `corex_vecs_1` (MemoryDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'corex_vecs_1_t': array([[0.00499143, 0.00928589, 0.25512596, ..., 0.50668709, 0.36728744,\n",
       "         0.5175123 ],\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50674074, 0.36716366,\n",
       "         0.51651723],\n",
       "        [0.01012107, 0.33417068, 0.01165398, ..., 0.50668775, 0.36724049,\n",
       "         0.51743167],\n",
       "        ...,\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50673889, 0.36725315,\n",
       "         0.51778256],\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50670132, 0.36724448,\n",
       "         0.51755399],\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50670218, 0.36724525,\n",
       "         0.51750522]]),\n",
       " 'report': '              precision    recall  f1-score   support\\n\\n           0       0.77      0.59      0.67       271\\n           1       0.83      0.92      0.87       599\\n\\n    accuracy                           0.82       870\\n   macro avg       0.80      0.76      0.77       870\\nweighted avg       0.81      0.82      0.81       870\\n',\n",
       " 'corex_vecs_1': array([[0.00499143, 0.00928589, 0.01165398, ..., 0.5067344 , 0.3673159 ,\n",
       "         0.51719942],\n",
       "        [0.00499143, 0.02025457, 0.01165398, ..., 0.50668024, 0.36673184,\n",
       "         0.51647581],\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50669563, 0.36728095,\n",
       "         0.51759919],\n",
       "        ...,\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50667256, 0.36770728,\n",
       "         0.51756409],\n",
       "        [0.00499143, 0.00928589, 0.01165398, ..., 0.50671373, 0.36723791,\n",
       "         0.51761051],\n",
       "        [0.00499143, 0.12423319, 0.09593206, ..., 0.50681247, 0.36712718,\n",
       "         0.51568222]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cfpb',\n",
       " 'news',\n",
       " 'countvectorizer',\n",
       " 'corex_model',\n",
       " 'parameters',\n",
       " 'params:target',\n",
       " 'params:columns',\n",
       " 'params:preprocess_out',\n",
       " 'params:n_components',\n",
       " 'params:input_column']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.io import DataCatalog, MemoryDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = DataCatalog(dict(xs=MemoryDataSet()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataCatalog' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0fafa1dee53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataCatalog' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "io['xs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
